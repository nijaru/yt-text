services:
  yt-text:
    build:
      context: .
      dockerfile: Dockerfile
    image: yt-text:${TAG:-production}
    container_name: yt-text-prod
    env_file:
      - .env
    environment:
      # Server Configuration
      - APP_ENV=production
      - APP_DEBUG=false
      - APP_HOST=0.0.0.0
      - APP_PORT=8000
      - APP_WORKERS=4
      - APP_DATABASE_URL=sqlite+aiosqlite:///data/db.sqlite
      - APP_DOCS_ENABLED=false
      
      # Performance
      - APP_CACHE_ENABLED=true
      - APP_MAX_CONCURRENT_JOBS=3
      - APP_RATE_LIMIT_ENABLED=true
      - APP_RATE_LIMIT_RPM=10
      - APP_RATE_LIMIT_DAILY=1000
      - APP_TRANSCRIPTION_TIMEOUT=1800
      
      # Model Configuration
      - APP_WHISPER_MODEL=base
      - APP_TRANSCRIPTION_BACKENDS=["whisper_cpp", "openai"]
      
      # Python Environment
      - PYTHONDONTWRITEBYTECODE=1
      - PYTHONUNBUFFERED=1
      - PYTHONPATH=/app

    ports:
      - "80:8000"
    volumes:
      - ./data:/data
      - ./cache:/cache
      - ./models:/models
      - ./logs:/logs
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    tmpfs:
      - /tmp:size=1G,noexec
    deploy:
      resources:
        limits:
          cpus: "2.0"
          memory: 4G
        reservations:
          cpus: "1.0"
          memory: 2G
    ulimits:
      nproc: 65535
      nofile:
        soft: 20000
        hard: 40000
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "10"
        compress: "true"
    networks:
      - yt-text-network

networks:
  yt-text-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
